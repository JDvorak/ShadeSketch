# Shade Sketches
[![Run on Ainize](https://www.ainize.ai/static/images/run_on_ainize_button.svg)](https://ainize.web.app/redirect?git_repo=github.com/vyvydkf628/ShadeSketch)
This repository provides an API server, called ShadeSketch, that generate detailed and accurate artistic shadows from pairs of line drawing sketches and lighting directions.


# Learning to Shadow Hand-drawn Sketches

Official Implementation of "Learning to Shadow Hand-drawn Sketches".

*IEEE Conference on Computer Vision and Pattern Recognition* **CVPR 2020 (Oral)**

[Project Site](https://cal.cs.umbc.edu/Papers/Zheng-2020-Shade) | [Paper](https://arxiv.org/abs/2002.11812) | Training Code, Online Demo and Dataset (coming soon)

## Overview

![Image of flowchart](https://github.com/qyzdao/Learn_to_Shade_Sketch/blob/master/images/overview.png)

We present a fully automatic method to generate detailed and accurate artistic shadows from pairs of line drawing sketches and lighting directions. We also contribute a new dataset of one thousand examples of pairs of line drawings and shadows that are tagged with lighting directions. Remarkably, the generated shadows quickly communicate the underlying 3D structure of the sketched scene. Consequently, the shadows generated by our approach can be used directly or as an excellent starting point for artists. We demonstrate that the deep learning network we propose takes a hand-drawn sketch, builds a 3D model in latent space, and renders the resulting shadows. The generated shadows respect the hand-drawn lines and underlying 3D space and contain sophisticated and accurate details, such as self-shadowing effects. Moreover, the generated shadows contain artistic effects, such as rim lighting or halos appearing from back lighting, that would be achievable with traditional 3D rendering methods.

## Prerequisites

- python3
- tensorflow
- numpy
- opencv-python
- argparse

```
sudo pip3 install -r requirements.txt
```

## How to Use

**Predict from arbitary lighting direction:**
```
python3 main.py --image-size=320 --direction=810
```
--direction choice: 001, 002 or xy0, where x={1,2,3,4,5,6,7,8} and y={1,2,3}.

**Predict gif:**
```
python3 main_gif.py --image-size=320 --dir='[image_name].png'
```
This command will result 80 frames in ./[image_name] folder. Copy makegif.py into ./[image_name] folder. Then:
```
cd [image_name]/
python3 makegif.py
```
## Dataset

The dataset will be released in the future. 

## Gallery

<img src="https://github.com/qyzdao/ShadeSketch/blob/master/images/26_710.png" width="200"><img src="https://github.com/qyzdao/ShadeSketch/blob/master/images/2_810.png" width="200"><img src="https://github.com/qyzdao/ShadeSketch/blob/master/images/47_710.png" width="150"><img src="https://github.com/qyzdao/ShadeSketch/blob/master/images/5_410.png" width="200">

<img src="https://github.com/qyzdao/ShadeSketch/blob/master/images/girl-210.gif" width="200"><img src="https://github.com/qyzdao/ShadeSketch/blob/master/images/girl-810.gif" width="200"><img src="https://github.com/qyzdao/ShadeSketch/blob/master/images/b.gif" width="200"><img src="https://github.com/qyzdao/ShadeSketch/blob/master/images/c.gif" width="200">

<img src="https://github.com/qyzdao/ShadeSketch/blob/master/images/11-top.gif" width="200"><img src="https://github.com/qyzdao/ShadeSketch/blob/master/images/continuous_lighting_1/810-830.gif" width="200"><img src="https://github.com/qyzdao/ShadeSketch/blob/master/images/continuous_lighting_1/front-lighting2.gif" width="200"><img src="https://github.com/qyzdao/ShadeSketch/blob/master/images/continuous_lighting_1/side-lighting2.gif" width="200">

<img src="https://github.com/qyzdao/ShadeSketch/blob/master/images/13-top.gif" width="200"><img src="https://github.com/qyzdao/ShadeSketch/blob/master/images/continuous_lighting_2/front-lighting-41600.gif" width="200"><img src="https://github.com/qyzdao/ShadeSketch/blob/master/images/continuous_lighting_2/side-lighting-41600.gif" width="200"><img src="https://github.com/qyzdao/ShadeSketch/blob/master/images/60-top.gif" width="200">

<img src="https://github.com/qyzdao/ShadeSketch/blob/master/images/4-top-25800.gif" width="200"><img src="https://github.com/qyzdao/ShadeSketch/blob/master/images/4_front_41600.gif" width="200"><img src="https://github.com/qyzdao/ShadeSketch/blob/master/images/4_side_25800.gif" width="200"><img src="https://github.com/qyzdao/ShadeSketch/blob/master/images/60_front_25800.gif" width="200">

<img src="https://github.com/qyzdao/ShadeSketch/blob/master/images/42-top.gif" width="200"><img src="https://github.com/qyzdao/ShadeSketch/blob/master/images/42-front-lighting-25800.gif" width="200"><img src="https://github.com/qyzdao/ShadeSketch/blob/master/images/42-side-lighting-25800.gif" width="200"><img src="https://github.com/qyzdao/ShadeSketch/blob/master/images/soft1.gif" width="200">

## License

Models are available under Creative Commons BY-NC 4.0 license. You can use, redistribute the models for **non-commercial purposes**.

## Citation

If you use our work or dataset, please cite our paper.
```
@InProceedings{Zheng2020LSHS,
title = {Learning to Shadow Hand-drawn Sketches},
author = {Zheng, Qingyuan and Li, Zhuoru and Bargteil, Adam},
booktitle = {Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition},
year = {2020}
}
```

## Credits

Sketches were collected from nico-opendata and web. animation sketches (c) Yoshinari Yo.

For training line normalization model, please see [LineNormalizer](https://github.com/hepesu/LineNormalizer).
